import streamlit as st
import google.generativeai as genai
import json
import re
import time
from PIL import Image
import random
import textwrap

# ==========================================
# 1. C·∫§U H√åNH API & PROMPT
# ==========================================

ALL_KEYS = st.secrets["GEMINI_API_KEYS"]

def generate_content_with_failover(prompt, image=None):
    """H√†m th√¥ng minh t·ª± ƒë·ªông d√≤ t√¨m Model t·ªët nh·∫•t c√≥ s·∫µn l∆∞·ª£t d√πng"""
    keys_to_try = list(ALL_KEYS)
    random.shuffle(keys_to_try) 
    
    # DANH S√ÅCH ∆ØU TI√äN (Gi·ªØ nguy√™n theo y√™u c·∫ßu c·ªßa b·∫°n)
    model_priority = [
        #"gemini-2.0-flash-thinking-preview-01-21",
        #"gemini-3-pro-preview", 
        #"gemini-2.5-pro",
        "gemini-3-flash-preview",        
        "gemini-2.5-flash",
        "gemini-2.5-flash-lite",
        "gemini-2.0-flash",
        "gemini-1.5-pro", 
        "gemini-1.5-flash"
    ]
    
    last_error = ""
    for index, current_key in enumerate(keys_to_try): # Th√™m index ƒë·ªÉ theo d√µi s·ªë th·ª© t·ª± Key
        try:
            genai.configure(api_key=current_key)
            
            # L·∫•y danh s√°ch c√°c model m√† Key n√†y TH·ª∞C S·ª∞ c√≥ quy·ªÅn truy c·∫≠p
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            
            # T√¨m model t·ªët nh·∫•t
            sel_model = None
            for target in model_priority:
                if any(target in m_name for m_name in available_models):
                    sel_model = target
                    break
            
            if not sel_model:
                sel_model = "gemini-1.5-flash" 

            # --- [PH·∫¶N TH√äM M·ªöI] HI·ªÇN TH·ªä TH√îNG TIN MODEL ---
            # 1. T·∫°o m·∫∑t n·∫° cho Key (Ch·ªâ hi·ªán 4 s·ªë cu·ªëi ƒë·ªÉ b·∫£o m·∫≠t)
            masked_key = f"****{current_key[-4:]}"
            
            # 2. Hi·ªÉn th·ªã th√¥ng b√°o nh·ªè g√≥c m√†n h√¨nh (Toast)
            st.toast(f"‚ö° ƒê√£ k·∫øt n·ªëi: {sel_model}", icon="ü§ñ")
            
            # 3. Hi·ªÉn th·ªã chi ti·∫øt trong giao di·ªán (T√πy ch·ªçn: D√πng Expander ƒë·ªÉ kh√¥ng r·ªëi m·∫Øt)
            with st.expander("üîå Technical Connection Details (Debug)", expanded=False):
                st.write(f"**Active Model:** `{sel_model}`")
                st.write(f"**Active API Key:** `{masked_key}` (Key #{index + 1})")
                if "thinking" in sel_model.lower():
                    st.caption("üß† Thinking Mode: ON")
            # ------------------------------------------------
            
            # Kh·ªüi t·∫°o model
            temp_model = genai.GenerativeModel(
                model_name=sel_model, 
                # system_instruction=GRADING_PROMPT_TEMPLATE # B·ªè comment d√≤ng n√†y n·∫øu b·∫°n ƒë√£ define bi·∫øn n√†y ·ªü ngo√†i
            )
            
            content_parts = [prompt]
            if image:
                content_parts.append(image)
                
             # C·∫•u h√¨nh Generation Config
            gen_config = {
                "temperature": 0.3,       # TƒÉng nh·∫π t·ª´ 0.1 l√™n 0.3 ƒë·ªÉ AI gi·∫£i th√≠ch phong ph√∫ h∆°n
                "top_p": 0.95,            # Cho ph√©p AI ch·ªçn t·ª´ v·ª±ng ƒëa d·∫°ng h∆°n
                "top_k": 64,              # Gi√∫p c√¢u vƒÉn m∆∞·ª£t m√† v√† s√¢u s·∫Øc h∆°n
                "max_output_tokens": 32000, # ƒê·∫£m b·∫£o AI c√≥ ƒë·ªß "ƒë·∫•t" ƒë·ªÉ vi·∫øt b·∫£n ph√¢n t√≠ch d√†i
            }

            # N·∫øu l√† model Thinking th√¨ th√™m c·∫•u h√¨nh suy lu·∫≠n
            if "thinking" in sel_model.lower():
                gen_config["thinking_config"] = {
                    "include_thoughts": True,
                    "thinking_budget": 32000 # ƒê·∫©y max ng√¢n s√°ch suy nghƒ©
                }

            # Th·ª±c hi·ªán g·ªçi API
            response = temp_model.generate_content(
                content_parts,
                generation_config=gen_config
            )
            
            # Tr·∫£ v·ªÅ k·∫øt qu·∫£ v√† t√™n model ƒë·ªÉ hi·ªÉn th·ªã th√™m n·∫øu c·∫ßn
            return response, sel_model 
            
        except Exception as e:
            last_error = str(e)
            if "429" in last_error or "quota" in last_error.lower() or "limit" in last_error.lower():
                continue 
            else:
                break
                
    st.error(f"‚ùå To√†n b·ªô {len(keys_to_try)} Keys ƒë√£ h·∫øt h·∫°n m·ª©c. L·ªói cu·ªëi: {last_error}")
    return None, None 

# Prompt "kh·ªßng" t·ª´ file gemini.ts c·ªßa b·∫°n
GRADING_PROMPT_TEMPLATE = """
B·∫°n h√£y ƒë√≥ng vai tr√≤ l√† "Examiner Tony". Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë·ªçc b√†i vi·∫øt d∆∞·ªõi ƒë√¢y v√† t·∫°o ra m·ªôt b√°o c√°o ph√¢n t√≠ch theo phong c√°ch "Inline Annotation".

**Y√äU C·∫¶U ƒê·ªäNH D·∫†NG OUTPUT (B·∫ÆT BU·ªòC):**
K·∫øt qu·∫£ tr·∫£ v·ªÅ ph·∫£i c√≥ 2 ph·∫ßn, ngƒÉn c√°ch b·ªüi d·∫•u "---":
1.  **Ph·∫ßn 1 (B√†i vi·∫øt ƒë√£ highlight):** Copy l·∫°i to√†n b·ªô b√†i vi·∫øt c·ªßa th√≠ sinh. V·ªõi m·ªói ƒëo·∫°n vƒÉn c√≥ l·ªói ho·∫∑c ƒëi·ªÉm c·∫ßn b√¨nh lu·∫≠n, h√£y b·ªçc ƒëo·∫°n ƒë√≥ trong th·∫ª `<span>` c√≥ class t∆∞∆°ng ·ª©ng (v√≠ d·ª•: `<span class="comment-tg1">...</span>`).
2.  **Ph·∫ßn 2 (Danh s√°ch b√¨nh lu·∫≠n):** Li·ªát k√™ c√°c b√¨nh lu·∫≠n chi ti·∫øt, m·ªói b√¨nh lu·∫≠n b·∫Øt ƒë·∫ßu b·∫±ng `Commented [TG...]:`.

**V√ç D·ª§ OUTPUT M·∫™U:**
<span class="comment-tg1">The line graph gives information about...</span>
<span class="comment-tg2">Overall, it is clear that the amount of money...</span>
<span class="comment-tg3">Looking at the graph in more detail...</span>
---
**Commented [TG1]:** See LR.
**Commented [TG2]:** Clear overview. You could add that all asset classes except for company shares saw significant rises from around 2006.
**Commented [TG3]:** I'd group these two ‚Äì both saw investment values fluctuate...

**QUY T·∫ÆC PH√ÇN T√çCH:**
*   **T∆∞ duy "I'd do this":** Khi ƒë∆∞a ra g·ª£i √Ω, h√£y d√πng vƒÉn phong c√° nh√¢n, v√≠ d·ª•: *"I'd group these two..."* ho·∫∑c *"You could add that..."*.
*   **T·∫≠p trung v√†o Logic & Omission:** ∆Øu ti√™n b·∫Øt c√°c l·ªói v·ªÅ t∆∞ duy d·ªØ li·ªáu, c√°ch nh√≥m th√¥ng tin, v√† s·ª± thi·∫øu s√≥t chi ti·∫øt.
"""

# ==========================================
# 2. C·∫§U H√åNH GIAO DI·ªÜN (T·ª´ index.html & styles)
# ==========================================
st.set_page_config(page_title="IELTS Examiner Pro", page_icon="üõ°Ô∏è", layout="wide")

# CSS ƒë·ªÉ t√°i t·∫°o giao di·ªán React (M√†u s·∫Øc, Font Merriweather/Inter, Error Cards)
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Merriweather:wght@300;400;700&display=swap');
    
    /* Font v√† m√†u s·∫Øc Global */
    html, body, [class*="css"] {
        font-family: 'Inter', sans-serif;
    }
    
    /* Style cho Header */
    h1 {
        font-family: 'Merriweather', serif !important;
        color: #0F172A !important;
        font-weight: 700 !important;
    }
    .pro-badge {
        color: #D40E14; 
        font-weight: bold;
    }
    .verified-badge {
        background-color: #F1F5F9;
        border: 1px solid #E2E8F0;
        padding: 4px 12px;
        border-radius: 99px;
        font-size: 14px;
        font-weight: bold;
        color: #475569;
        display: inline-flex;
        align-items: center;
        margin-left: 10px;
    }
    
    /* Style cho Error Cards (Gi·ªëng MessageBubble.tsx) */
    .error-card {
        background-color: white;
        border: 1px solid #E5E7EB;
        border-radius: 12px;
        padding: 20px;
        margin-bottom: 16px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.05);
        transition: all 0.2s;
    }
    .error-card:hover {
        box-shadow: 0 4px 6px rgba(0,0,0,0.05);
        border-color: #D1D5DB;
    }
    .error-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 12px;
        border-bottom: 1px solid #F3F4F6;
        padding-bottom: 8px;
    }
    .error-badge-grammar {
        background-color: #DCFCE7;
        border: 1px solid #22C55E;
        color: #022C22;
        padding: 2px 8px;
        border-radius: 6px;
        font-size: 14px;
        font-weight: 800;
        text-transform: uppercase;
    }
    .error-badge-vocab {
        background-color: #FEF9C3;
        border: 1px solid #FCD34D;
        color: #713F12;
        padding: 2px 8px;
        border-radius: 6px;
        font-size: 14px;
        font-weight: 800;
        text-transform: uppercase;
    }
    .impact-high { background-color: #FEE2E2; color: #991B1B; padding: 2px 8px; border-radius: 99px; font-size: 14px; font-weight: bold; border: 1px solid #FECACA;}
    .impact-medium { background-color: #FFEDD5; color: #9A3412; padding: 2px 8px; border-radius: 99px; font-size: 14px; font-weight: bold; border: 1px solid #FED7AA;}
    .impact-low { background-color: #DBEAFE; color: #1E40AF; padding: 2px 8px; border-radius: 99px; font-size: 14px; font-weight: bold; border: 1px solid #BFDBFE;}
    
    .correction-box {
        background-color: #F9FAFB;
        padding: 12px;
        border-radius: 8px;
        margin-bottom: 12px;
        font-size: 16px;
        border: 1px solid #F3F4F6;
    }
    
    /* Style cho Annotated Essay */
    .annotated-text {
        font-family: 'Merriweather', serif;
        line-height: 1.8;
        color: #374151;
        background-color: white;
        padding: 24px;
        border-radius: 12px;
        border: 1px solid #E5E7EB;
        box-shadow: 0 1px 2px rgba(0,0,0,0.05);
    }
    del {
        color: #9CA3AF;
        text-decoration: line-through;
        margin-right: 4px;
        text-decoration-thickness: 2px;
    }
    ins.grammar {
        background-color: #4ADE80;
        color: #022C22;
        text-decoration: none;
        padding: 2px 6px;
        border-radius: 4px;
        font-weight: 700;
        border: 1px solid #22C55E;
    }
    ins.vocab {
        background-color: #FDE047;
        color: #000;
        text-decoration: none;
        padding: 2px 6px;
        border-radius: 4px;
        font-weight: 700;
        border: 1px solid #FCD34D;
    }
    
    /* Button Style */
    div.stButton > button {
        background-color: #D40E14;
        color: white;
        font-weight: bold;
        border: none;
        padding: 10px 24px;
        border-radius: 8px;
        transition: all 0.3s;
    }
    div.stButton > button:hover {
        background-color: #B91C1C;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
    }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 3. LOGIC K·∫æT N·ªêI AI & X·ª¨ L√ù D·ªÆ LI·ªÜU
# ==========================================

import html
import os
import requests
import re
import time
from io import BytesIO

# Th∆∞ vi·ªán Word
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

# Th∆∞ vi·ªán PDF
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.fonts import addMapping

# --- H√ÄM T·ª∞ ƒê·ªòNG T·∫¢I & ƒêƒÇNG K√ù FONT ROBOTO (H·ªñ TR·ª¢ TI·∫æNG VI·ªÜT) ---
def clean_json(text):
    """Tr√≠ch xu·∫•t JSON t·ª´ ph·∫£n h·ªìi c·ªßa AI"""
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text)
    if match:
        content = match.group(1)
        content = re.sub(r'[\x00-\x1F\x7F-\x9F]', '', content)
        return content.strip()
    return None

def calculate_overall(scores):
    """H√†m ph·ª•: T·ª± t√≠nh ƒëi·ªÉm Overall chu·∫©n IELTS t·ª´ 4 ƒëi·ªÉm th√†nh ph·∫ßn"""
    try:
        # L·ªçc b·ªè c√°c gi√° tr·ªã kh√¥ng ph·∫£i s·ªë
        valid_scores = []
        for s in scores:
            try:
                valid_scores.append(float(s))
            except:
                continue
                
        if not valid_scores or len(valid_scores) < 4: return '-'
        
        avg = sum(valid_scores) / len(valid_scores)
        decimal = avg - int(avg)
        
        # Quy t·∫Øc l√†m tr√≤n IELTS (.25 l√™n .5, .75 l√™n 1.0)
        if decimal < 0.25: final = int(avg)
        elif decimal < 0.75: final = int(avg) + 0.5
        else: final = int(avg) + 1.0
        
        return str(final)
    except:
        return '-'

def process_response(full_text):
    """
    1. T√°ch JSON ƒë·ªÉ l·∫•y danh s√°ch l·ªói v√† b√†i s·ª≠a.
    2. D√πng Regex qu√©t vƒÉn b·∫£n Markdown ƒë·ªÉ l·∫•y ƒëi·ªÉm G·ªëc (Original Score).
    """
    json_str = clean_json(full_text)
    markdown_part = full_text
    
    # Kh·ªüi t·∫°o c·∫•u tr√∫c d·ªØ li·ªáu m·∫∑c ƒë·ªãnh
    data = {
        "errors": [], 
        "annotatedEssay": None, 
        "revisedScore": None, 
        "originalScore": {
            "task_achievement": "-",
            "cohesion_coherence": "-",
            "lexical_resource": "-",
            "grammatical_range": "-",
            "overall": "-"
        }
    }
    
    # A. X·ª≠ l√Ω JSON (Ch·ªß y·∫øu ƒë·ªÉ l·∫•y L·ªói v√† B√†i s·ª≠a)
    if json_str:
        markdown_part = full_text.split("```json")[0].strip()
        try:
            parsed = json.loads(json_str)
            data["errors"] = parsed.get("errors", [])
            data["annotatedEssay"] = parsed.get("annotated_essay")
            data["revisedScore"] = parsed.get("revised_score")
        except json.JSONDecodeError:
            pass

    # B. QUAN TR·ªåNG: COPY ƒêI·ªÇM T·ª™ VƒÇN B·∫¢N (Regex Scanning)
    patterns = {
        "task_achievement": r"ƒêi·ªÉm\s+Task\s+Achievement.*?(\d+\.?\d*)",
        "cohesion_coherence": r"ƒêi·ªÉm\s+Coherence.*?(\d+\.?\d*)",
        "lexical_resource": r"ƒêi·ªÉm\s+Lexical.*?(\d+\.?\d*)",
        "grammatical_range": r"ƒêi·ªÉm\s+Grammatical.*?(\d+\.?\d*)",
    }
    
    found_scores = []
    
    # Qu√©t t·ª´ng ti√™u ch√≠ trong vƒÉn b·∫£n markdown
    for key, regex in patterns.items():
        match = re.search(regex, markdown_part, re.IGNORECASE | re.DOTALL)
        if match:
            score = match.group(1) # L·∫•y con s·ªë t√¨m ƒë∆∞·ª£c
            data["originalScore"][key] = score
            found_scores.append(score)
        else:
            # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ t√¨m trong JSON d·ª± ph√≤ng
            try:
                if json_str:
                    parsed = json.loads(json_str)
                    val = parsed.get("original_score", {}).get(key, "-")
                    data["originalScore"][key] = str(val)
                    if str(val) != "-": found_scores.append(val)
            except:
                pass

    # C. T·ª± t√≠nh Overall t·ª´ c√°c ƒëi·ªÉm v·ª´a t√¨m ƒë∆∞·ª£c
    if found_scores:
        data["originalScore"]["overall"] = calculate_overall(found_scores)

    return markdown_part, data

# --- 2. C√ÅC H√ÄM XU·∫§T FILE (FILE EXPORT) ---

def register_vietnamese_font():
    """T·∫£i v√† ƒëƒÉng k√Ω font Roboto t·ª´ Google Fonts (Github Source)"""
    font_reg = "Roboto-Regular.ttf"
    font_bold = "Roboto-Bold.ttf"
    
    # URL m·ªõi ch√≠nh x√°c (D√πng kho 'src/hinted' c·ªßa googlefonts)
    urls = {
        font_reg: "https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf",
        font_bold: "https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Bold.ttf"
    }
    
    # Headers gi·∫£ l·∫≠p tr√¨nh duy·ªát ƒë·ªÉ tr√°nh l·ªói 403/404
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }

    try:
        # 1. T·∫£i font v·ªÅ n·∫øu ch∆∞a c√≥ ho·∫∑c file b·ªã l·ªói (0kb)
        for filename, url in urls.items():
            if os.path.exists(filename) and os.path.getsize(filename) < 1000:
                os.remove(filename) # X√≥a file l·ªói
                
            if not os.path.exists(filename):
                response = requests.get(url, headers=headers, timeout=20)
                if response.status_code == 200:
                    with open(filename, "wb") as f:
                        f.write(response.content)
                else:
                    print(f"‚ùå Kh√¥ng t·∫£i ƒë∆∞·ª£c {filename}. M√£ l·ªói: {response.status_code}")

        # 2. ƒêƒÉng k√Ω v·ªõi ReportLab
        if os.path.exists(font_reg) and os.path.exists(font_bold):
            pdfmetrics.registerFont(TTFont('Roboto', font_reg))
            pdfmetrics.registerFont(TTFont('Roboto-Bold', font_bold))
            addMapping('Roboto', 0, 0, 'Roboto') # Normal
            addMapping('Roboto', 1, 0, 'Roboto-Bold') # Bold
            return True
        else:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file font sau khi t·∫£i.")
            return False
            
    except Exception as e:
        print(f"‚ùå L·ªói x·ª≠ l√Ω font: {e}")
        return False

# H√ÄM T·∫†O FILE WORD
def create_docx(data, topic, original_essay, analysis_text):
    doc = Document()
    
    # Header
    heading = doc.add_heading('IELTS WRITING TASK 1 - ASSESSMENT REPORT', 0)
    heading.alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_paragraph(f"Date: {time.strftime('%d/%m/%Y')}")
    
    # 1. BAND SCORE
    doc.add_heading('1. BAND SCORE', level=1)
    scores = data.get("originalScore")
    
    if scores and isinstance(scores, dict) and scores.get('overall', '-') != '-':
        table = doc.add_table(rows=2, cols=5)
        table.style = 'Table Grid'
        
        headers = ['Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar', 'OVERALL']
        for i, h in enumerate(headers):
            cell = table.cell(0, i)
            cell.text = h
            cell.paragraphs[0].runs[0].bold = True
        
        vals = [
            str(scores.get('task_achievement', '-')),
            str(scores.get('cohesion_coherence', '-')),
            str(scores.get('lexical_resource', '-')),
            str(scores.get('grammatical_range', '-')),
            str(scores.get('overall', '-'))
        ]
        for i, v in enumerate(vals):
            table.cell(1, i).text = v
    else:
        doc.add_paragraph("Score details could not be extracted automatically.")

    # 2. ANALYSIS
    doc.add_heading('2. EXAMINER\'S DETAILED ANALYSIS', level=1)
    if analysis_text:
        clean_analysis = analysis_text.replace('**', '').replace('### ', '').replace('#### ', '')
        doc.add_paragraph(clean_analysis)

    # 3. ERRORS
    doc.add_heading('3. DETAILED ERROR LOG', level=1)
    if data.get("errors"):
        for err in data['errors']:
            p = doc.add_paragraph(style='List Bullet')
            runner = p.add_run(f"[{err['category']} - {err['type']}]: ")
            runner.bold = True
            runner.font.color.rgb = RGBColor(200, 0, 0)
            p.add_run(f" '{err['original']}' ‚Üí '{err['correction']}'")
            p.add_run(f"\n   Reason: {err['explanation']}")
    else:
        doc.add_paragraph("No specific errors detected.")

    # APPENDIX
    doc.add_page_break()
    doc.add_heading('APPENDIX', level=1)
    doc.add_heading('A. Task Prompt:', level=2)
    doc.add_paragraph(topic)
    doc.add_heading('B. Original Essay:', level=2)
    doc.add_paragraph(original_essay)
    doc.add_heading('C. Annotated Version:', level=2)
    clean_annotated = re.sub(r'<[^>]+>', '', data.get("annotatedEssay", "") or "")
    doc.add_paragraph(clean_annotated)

    # D. PROJECTED SCORE
    doc.add_heading('D. PROJECTED BAND SCORE (AFTER REVISION)', level=2)
    rev_scores = data.get("revisedScore")
    if rev_scores:
        table = doc.add_table(rows=2, cols=5)
        table.style = 'Table Grid'
        vals = [
            str(rev_scores.get('task_achievement', '-')),
            str(rev_scores.get('cohesion_coherence', '-')),
            str(rev_scores.get('lexical_resource', '-')),
            str(rev_scores.get('grammatical_range', '-')),
            str(rev_scores.get('overall', '-'))
        ]
        # Header
        for i, h in enumerate(['Task Achievement', 'Coherence', 'Lexical Resource', 'Grammar', 'OVERALL']):
            cell = table.cell(0, i)
            cell.text = h
            cell.paragraphs[0].runs[0].bold = True
            cell.paragraphs[0].runs[0].font.color.rgb = RGBColor(0, 100, 0)
        # Value
        for i, v in enumerate(vals):
            table.cell(1, i).text = v
            
        if rev_scores.get('logic_re_evaluation'):
            p = doc.add_paragraph()
            run = p.add_run(f"\nExaminer's Note: {rev_scores['logic_re_evaluation']}")
            run.font.italic = True
            run.font.color.rgb = RGBColor(0, 128, 0)

    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

# H√ÄM T·∫†O FILE PDF
def create_pdf(data, topic, original_essay, analysis_text):
    # 1. ƒêƒÉng k√Ω Font
    has_font = register_vietnamese_font()
    font_name = 'Roboto' if has_font else 'Helvetica'
    font_bold = 'Roboto-Bold' if has_font else 'Helvetica-Bold'

    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    
    # 2. L·∫•y Styles
    styles = getSampleStyleSheet()
    
    # 3. C·∫≠p nh·∫≠t Font
    styles['Title'].fontName = font_name
    styles['Title'].fontSize = 18
    styles['Heading1'].fontName = font_bold
    styles['Heading2'].fontName = font_bold
    styles['Normal'].fontName = font_name
    styles['Normal'].fontSize = 13
    
    h1_style = styles['Heading1']
    h2_style = styles['Heading2']
    normal_style = styles['Normal']
    
    elements = []

    # Title
    elements.append(Paragraph("IELTS WRITING ASSESSMENT REPORT", styles['Title']))
    elements.append(Spacer(1, 12))

    # 1. BAND SCORE
    elements.append(Paragraph("1. BAND SCORE", h1_style))
    scores = data.get("originalScore")
    
    if scores and isinstance(scores, dict) and scores.get('overall', '-') != '-':
        data_table = [
            ['TA', 'CC', 'LR', 'GRA', 'OVERALL'],
            [
                str(scores.get('task_achievement', '-')),
                str(scores.get('cohesion_coherence', '-')),
                str(scores.get('lexical_resource', '-')),
                str(scores.get('grammatical_range', '-')),
                str(scores.get('overall', '-'))
            ]
        ]
        t = Table(data_table, colWidths=[60, 60, 60, 60, 80])
        t.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.darkred),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 0), (-1, -1), font_name) 
        ]))
        elements.append(t)
    else:
        elements.append(Paragraph("Original score data not found.", normal_style))
    
    elements.append(Spacer(1, 12))

    # 2. ANALYSIS
    elements.append(Paragraph("2. DETAILED ANALYSIS", h1_style))
    if analysis_text:
        safe_text = html.escape(analysis_text).replace('\n', '<br/>').replace('**', '').replace('###', '')
        elements.append(Paragraph(safe_text, normal_style))
    else:
        elements.append(Paragraph("No detailed analysis available.", normal_style))
    elements.append(Spacer(1, 12))

    # 3. ERRORS
    elements.append(Paragraph("3. ERROR LOG", h1_style))
    if data.get("errors"):
        for err in data['errors']:
            cat = html.escape(str(err.get('category', '')))
            typ = html.escape(str(err.get('type', '')))
            orig = html.escape(str(err.get('original', '')))
            fix = html.escape(str(err.get('correction', '')))
            text = f"<b>[{cat}] {typ}</b><br/>Original: <strike>{orig}</strike> -> Fix: <b>{fix}</b>"
            elements.append(Paragraph(text, normal_style))
            elements.append(Spacer(1, 6))

    # APPENDIX
    elements.append(PageBreak())
    elements.append(Paragraph("APPENDIX", h1_style))
    
    elements.append(Paragraph("<b>A. Task Prompt:</b>", h2_style))
    elements.append(Paragraph(html.escape(topic).replace('\n', '<br/>'), normal_style))
    elements.append(Spacer(1, 10))
    
    elements.append(Paragraph("<b>B. Original Essay:</b>", h2_style))
    elements.append(Paragraph(html.escape(original_essay).replace('\n', '<br/>'), normal_style))
    elements.append(Spacer(1, 10))

    elements.append(Paragraph("<b>C. Annotated Version:</b>", h2_style))
    clean_annotated = re.sub(r'<[^>]+>', '', data.get("annotatedEssay", "") or "")
    elements.append(Paragraph(html.escape(clean_annotated).replace('\n', '<br/>'), normal_style))
    elements.append(Spacer(1, 10))

    # D. PROJECTED
    elements.append(Paragraph("<b>D. PROJECTED BAND SCORE (AFTER REVISION):</b>", h2_style))
    rev_scores = data.get("revisedScore")
    if rev_scores:
        rev_table_data = [
            ['TA', 'CC', 'LR', 'GRA', 'OVERALL'],
            [
                str(rev_scores.get('task_achievement', '-')),
                str(rev_scores.get('cohesion_coherence', '-')),
                str(rev_scores.get('lexical_resource', '-')),
                str(rev_scores.get('grammatical_range', '-')),
                str(rev_scores.get('overall', '-'))
            ]
        ]
        t2 = Table(rev_table_data, colWidths=[60, 60, 60, 60, 80])
        t2.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, 0), colors.darkgreen),
            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
            ('GRID', (0, 0), (-1, -1), 1, colors.black),
            ('FONTNAME', (0, 0), (-1, -1), font_name)
        ]))
        elements.append(t2)
        
        if rev_scores.get('logic_re_evaluation'):
            safe_note = html.escape(rev_scores['logic_re_evaluation'])
            elements.append(Spacer(1, 6))
            elements.append(Paragraph(f"<i>Examiner's Note: {safe_note}</i>", normal_style))

    doc.build(elements)
    buffer.seek(0)
    return buffer
    
# ==========================================
# 4. GIAO DI·ªÜN CH√çNH (UI)
# ==========================================
import textwrap

# HEADER (Thanh ti√™u ƒë·ªÅ v√† n√∫t x√≥a)
c1, c2 = st.columns([3, 1])
with c1:
    st.markdown("""
        <div style="display: flex; flex-direction: column; justify-content: center;">
            <h1 style="margin-bottom: 5px; line-height: 0.2rem;">
                IELTS Examiner <span class='pro-badge'>Pro</span>
            </h1>
            <div>
                <span class='verified-badge' style="margin-left: 2px;">
                    üõ°Ô∏è BC CERTIFIED EXPERT
                </span>
            </div>
        </div>
    """, unsafe_allow_html=True)
with c2:
    if st.button("üóëÔ∏è Clear Session", use_container_width=True):
        st.session_state.messages = []
        st.session_state.submitted = False 
        st.rerun()

if "submitted" not in st.session_state:
    st.session_state.submitted = False

if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "ai",
            "content": """
<div style="font-family: 'Inter', sans-serif; color: #1F2937; line-height: 1.4; font-size: 16px; max-width: 850px;">
    <h3 style="color: #D40E14; font-family: 'Merriweather', serif; margin-top: 0; margin-bottom: 15px; font-size: 22px; border-bottom: 3px solid #D40E14; display: inline-block; padding-bottom: 5px;">
        Welcome to the Official Task 1 Assessment Room.
    </h3>
    <p style="margin-bottom: 13px;">
        This system provides expert-level evaluation of <b>IELTS Academic Task 1 reports</b>, based on the official IELTS band descriptors.
    </p>
    <p style="margin-bottom: 13px;">
        The assessment focuses on objective, criteria-based feedback to help you understand your current writing level and areas for improvement.
    </p>
    <div style="background-color: #F8FAFC; border-radius: 8px; padding: 15px 20px; border-left: 5px solid #D40E14; box-shadow: 0 2px 4px rgba(0,0,0,0.05);">
        <p style="margin-bottom: 10px; font-weight: 800; font-size: 13px; color: #111827; text-transform: uppercase; letter-spacing: 1px;">
            Guidelines for a valid submission:
        </p>
        <div style="color: #374151;">
            <div style="margin-bottom: 6px;">‚Ä¢ <b>Task Prompt:</b> Provide the original question or instruction.</div>
            <div style="margin-bottom: 6px;">‚Ä¢ <b>Visual Data:</b> Upload a clear image of the chart, graph, table, or diagram.</div>
            <div>‚Ä¢ <b>Written Report:</b> Paste your complete response (at least <b>150 words</b> to avoid penalties).</div>
        </div>
    </div>
</div>
""",
            "data": None
        }
    ]

# HI·ªÇN TH·ªä L·ªäCH S·ª¨ CHAT V√Ä K·∫æT QU·∫¢ CH·∫§M ƒêI·ªÇM
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar="üë®‚Äçüè´" if msg["role"] == "ai" else "üë§"):
        if msg["role"] == "user":
            if msg.get("topic"):
                st.markdown(f"**üìù Task Prompt:**\n> {msg['topic']}")
            if msg.get("image"):
                st.image(msg["image"], caption="Visual Resource Attached", width=400)
            st.write(msg["content"])
        else:
            # --- PH·∫¶N HI·ªÇN TH·ªä M·ªöI THEO PHONG C√ÅCH "COMMENT" ---
            
            # 1. T√ÅCH B√ÄI VI·∫æT V√Ä B√åNH LU·∫¨N T·ª™ K·∫æT QU·∫¢ C·ª¶A AI
            content_parts = msg["content"].split("\n---\n", 1)
            essay_html = content_parts[0]
            comments_text = content_parts[1] if len(content_parts) > 1 else ""

            # 2. PARSE C√ÅC B√åNH LU·∫¨N
            comments_dict = {}
            # D√πng Regex ƒë·ªÉ t√°ch t·ª´ng comment ra (TG1, TG2, ...)
            matches = re.findall(r"Commented\s*\[(TG\d+)\]:\s*([\s\S]*?)(?=\nCommented|\Z)", comments_text)
            for match in matches:
                tag_id = match[0].lower() # -> tg1, tg2
                comment_content = match[1].strip()
                comments_dict[tag_id] = comment_content

            # 3. T·∫†O HTML HO√ÄN CH·ªàNH V·ªöI TOOLTIP
            # Th√™m CSS cho tooltip
            st.markdown("""
            <style>
                .comment-highlight {
                    background-color: #fce7f3; /* M√†u h·ªìng nh·∫°t */
                    border-bottom: 2px dashed #db2777;
                    cursor: pointer;
                    position: relative;
                }
                .tooltip {
                    visibility: hidden;
                    width: 250px;
                    background-color: #3B82F6;
                    color: #fff;
                    text-align: left;
                    border-radius: 6px;
                    padding: 10px;
                    position: absolute;
                    z-index: 1;
                    bottom: 125%;
                    left: 50%;
                    margin-left: -125px;
                    opacity: 0;
                    transition: opacity 0.3s;
                }
                .comment-highlight:hover .tooltip {
                    visibility: visible;
                    opacity: 1;
                }
            </style>
            """, unsafe_allow_html=True)
            
            # Thay th·∫ø c√°c class trong HTML b·∫±ng th·∫ª c√≥ tooltip
            final_html = essay_html
            for tag_id, comment in comments_dict.items():
                replacement_html = f'''
                <span class="comment-highlight">
                    {tag_id.upper()}
                    <span class="tooltip">{comment}</span>
                </span>
                '''
                # T√¨m v√† thay th·∫ø th·∫ª span t∆∞∆°ng ·ª©ng
                final_html = re.sub(f'<span class="comment-{tag_id}">', f'<span class="comment-highlight">', final_html, flags=re.IGNORECASE)
                # Thay th·∫ø th·∫ª ƒë√≥ng, ƒë·ªìng th·ªùi ch√®n tooltip v√†o
                final_html = re.sub(r'</span>', f'{replacement_html}</span>', final_html, count=1)


            # 4. HI·ªÇN TH·ªä GIAO DI·ªÜN
            st.subheader("üìù Examiner's Review")
            st.markdown(final_html, unsafe_allow_html=True)
            
            # --- C√ÅC PH·∫¶N C√íN L·∫†I (B·∫¢NG ƒêI·ªÇM, DOWNLOAD...) ---
            # B·∫°n c√≥ th·ªÉ gi·ªØ l·∫°i ph·∫ßn hi·ªÉn th·ªã B·∫£ng ƒëi·ªÉm, n√∫t Download... ·ªü d∆∞·ªõi ƒë√¢y
            # V√≠ d·ª•:
            if msg.get("data") and msg["data"].get("revisedScore"):
                 scores = msg["data"]["revisedScore"]
                 st.markdown("### üìä Band Scores")
                 cols = st.columns(5)
                 # ... (code hi·ªÉn th·ªã ƒëi·ªÉm)
# ==========================================
# 5. KHU V·ª∞C NH·∫¨P LI·ªÜU & X·ª¨ L√ù AI (·∫®N KHI XONG)
# ==========================================

# Ch·ªâ hi·ªÉn th·ªã n·∫øu ch∆∞a n·ªôp b√†i
if not st.session_state.submitted:
    st.markdown("---")
    with st.container():
        # B·ªë c·ª•c b·∫•t ƒë·ªëi x·ª©ng: C·ªôt tr√°i 1.3 - C·ªôt ph·∫£i 2.7
        col_left, col_right = st.columns([1.3, 2.7], gap="large")
        
        with col_left:
            st.markdown("<p style='font-weight: 700; font-size: 15px; color: #1F2937;'>üìù TASK 1 QUESTION / PROMPT</p>", unsafe_allow_html=True)
            topic_input = st.text_area("topic_label", label_visibility="collapsed", height=280, placeholder="Paste the official question text here...")
            
            st.markdown("<div style='margin-top: 25px;'></div>", unsafe_allow_html=True)
            st.markdown("<p style='font-weight: 700; font-size: 15px; color: #1F2937;'>üìä VISUAL DATA</p>", unsafe_allow_html=True)
            uploaded_file = st.file_uploader("file_label", label_visibility="collapsed", type=['png', 'jpg', 'jpeg'])
            
        with col_right:
            st.markdown("<p style='font-weight: 700; font-size: 15px; color: #1F2937;'>‚úçÔ∏è YOUR WRITTEN REPORT</p>", unsafe_allow_html=True)
            essay_input = st.text_area("essay_label", label_visibility="collapsed", height=515, placeholder="Type or paste your response here (aim for 150+ words)...")

        st.markdown("<div style='margin-top: 20px;'></div>", unsafe_allow_html=True)
        submit_btn = st.button("üöÄ SUBMIT FOR ASSESSMENT", type="primary", use_container_width=True)

        if submit_btn:
            # KI·ªÇM TRA B·∫ÆT BU·ªòC NH·∫¨P ƒê·ª¶ 3 TH√îNG TIN
            if not topic_input.strip():
                st.warning("‚ö†Ô∏è B·∫Øt bu·ªôc: Vui l√≤ng nh·∫≠p ƒë·ªÅ b√†i (Task Prompt) tr∆∞·ªõc khi ch·∫•m ƒëi·ªÉm!")
            elif uploaded_file is None:
                st.warning("‚ö†Ô∏è B·∫Øt bu·ªôc: Vui l√≤ng t·∫£i l√™n h√¨nh ·∫£nh bi·ªÉu ƒë·ªì (Visual Data) ƒë·ªÉ Gi√°m kh·∫£o ƒë·ªëi chi·∫øu s·ªë li·ªáu!")
            elif not essay_input.strip() or len(essay_input.strip()) < 10:
                st.warning("‚ö†Ô∏è B·∫Øt bu·ªôc: Vui l√≤ng nh·∫≠p n·ªôi dung b√†i l√†m (√≠t nh·∫•t 10 k√Ω t·ª±)!")
            else:
                # N·∫æU ƒê√É NH·∫¨P ƒê·ª¶, B·∫ÆT ƒê·∫¶U QUY TR√åNH CH·∫§M ƒêI·ªÇM
                loading_steps = [
                    "üïµÔ∏è INITIAL VALIDATION: IDENTIFYING EXAM CONTEXT AND ENFORCING WORD COUNT CONSTRAINTS...",
                    "üîç EXHAUSTIVE ERROR SCANNING: CONDUCTING SENTENCE-BY-SENTENCE REVIEW FOR ALL ERRORS...",
                    "üìä DEEP CRITERIA ANALYSIS: EVALUATING TA, CC, LR, AND GRA STANDARDS WITH CEILING SCORES...",
                    "üßÆ SCORE CALCULATION: DETERMINING COMPONENT BANDS AND APPLYING IELTS ROUNDING RULES...",
                    "‚öñÔ∏è CONSISTENCY CHECK: CROSS-REFERENCING ASSIGNED SCORES WITH ERROR LOG FOR LOGICAL ACCURACY...",
                    "üìù OUTPUT GENERATION: COMPILING DETAILED ANALYSIS AND PRODUCING ANNOTATED ESSAY DATA..."
                ]
                
                status_container = st.status("üë®‚Äçüè´ Senior Examiner is starting assessment...", expanded=True)
                progress_bar = status_container.progress(0)
                
                try:
                    # 1. X·ª≠ l√Ω h√¨nh ·∫£nh
                    image_part = Image.open(uploaded_file)
                    
                    # 2. Gh√©p Prompt
                    full_prompt = GRADING_PROMPT_TEMPLATE.replace('{{TOPIC}}', topic_input).replace('{{ESSAY}}', essay_input)
                    
                    # 3. G·ªçi AI
                    response, used_model = generate_content_with_failover(full_prompt, image_part)
                    
                    # 4. Ch·∫°y hi·ªáu ·ª©ng Loading
                    for i, text in enumerate(loading_steps):
                        status_container.write(text)
                        progress_bar.progress(int((i + 1) * (100 / len(loading_steps))))
                        time.sleep(2.8) 
                    
                    if response:
                        markdown_text, parsed_data = process_response(response.text)
                        st.session_state.messages.append({"role": "user", "content": essay_input, "topic": topic_input, "image": uploaded_file})
                        st.session_state.messages.append({"role": "ai", "content": markdown_text, "data": parsed_data, "model_version": used_model})
                        st.session_state.submitted = True
                        status_container.update(label="‚úÖ ASSESSMENT COMPLETE!", state="complete", expanded=False)
                        st.rerun()
                        
                except Exception as e:
                    status_container.update(label="‚ùå Error occurred!", state="error")
                    st.error(f"L·ªói h·ªá th·ªëng: {e}")
# Footer
st.markdown("---")
st.caption("Developed by Albert Nguyen - v20251228.")




















