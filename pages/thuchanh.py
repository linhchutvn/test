import streamlit as st
import google.generativeai as genai
import json
import re
import time
import random
import textwrap
import html
import os
import requests
from PIL import Image
from io import BytesIO

# Th∆∞ vi·ªán Word & PDF
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from reportlab.lib.pagesizes import A4
from reportlab.lib import colors
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.fonts import addMapping

# ==========================================
# 1. C·∫§U H√åNH & CSS (STYLE CHU·∫®N)
# ==========================================
st.set_page_config(page_title="IELTS Writing Master", page_icon="üéì", layout="wide")

st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Merriweather:wght@300;400;700&display=swap');
    
    html, body, [class*="css"] { font-family: 'Inter', sans-serif; }
    
    .main-header { font-family: 'Merriweather', serif; color: #0F172A; font-weight: 700; font-size: 2.2rem; margin-bottom: 0.5rem; }
    .sub-header { font-family: 'Inter', sans-serif; color: #64748B; font-size: 1.1rem; margin-bottom: 2rem; border-bottom: 1px solid #E2E8F0; padding-bottom: 1rem; }
    .step-header { font-family: 'Inter', sans-serif; font-weight: 700; font-size: 1.2rem; color: #1E293B; margin-top: 1.5rem; margin-bottom: 0.5rem; }
    .guide-box { background-color: #f8f9fa; border-left: 5px solid #ff4b4b; padding: 15px; border-radius: 5px; margin-bottom: 10px; color: #31333F; }
    .error-card { background-color: white; border: 1px solid #E5E7EB; border-radius: 12px; padding: 20px; margin-bottom: 16px; box-shadow: 0 1px 3px rgba(0,0,0,0.05); transition: all 0.2s; }
    .annotated-text { font-family: 'Merriweather', serif; line-height: 1.8; color: #374151; background-color: white; padding: 24px; border-radius: 12px; border: 1px solid #E5E7EB; }
    
    del { color: #9CA3AF; text-decoration: line-through; margin-right: 4px; text-decoration-thickness: 2px; }
    ins.grammar { background-color: #4ADE80; color: #022C22; text-decoration: none; padding: 2px 6px; border-radius: 4px; font-weight: 700; border: 1px solid #22C55E; }
    ins.vocab { background-color: #FDE047; color: #000; text-decoration: none; padding: 2px 6px; border-radius: 4px; font-weight: 700; border: 1px solid #FCD34D; }
    
    div.stButton > button { background-color: #FF4B4B; color: white; font-weight: bold; border-radius: 8px; border: none; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. LOGIC AI (FAILOVER)
# ==========================================
try:
    ALL_KEYS = st.secrets["GEMINI_API_KEYS"]
except Exception:
    st.error("‚ö†Ô∏è Ch∆∞a c·∫•u h√¨nh secrets.toml ch·ª©a GEMINI_API_KEYS!")
    st.stop()

def generate_content_with_failover(prompt, image=None, json_mode=False):
    keys_to_try = list(ALL_KEYS)
    random.shuffle(keys_to_try) 
    model_priority = ["gemini-2.0-flash-thinking-preview-01-21", "gemini-3-flash-preview", "gemini-2.5-flash", "gemini-2.0-flash", "gemini-1.5-pro", "gemini-1.5-flash"]
    
    for current_key in keys_to_try: 
        try:
            genai.configure(api_key=current_key)
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            sel_model = next((m for m in model_priority if any(m in mn for mn in available_models)), "gemini-1.5-flash")
            
            temp_model = genai.GenerativeModel(model_name=sel_model)
            content_parts = [prompt]
            if image: content_parts.append(image)
            
            gen_config = {"temperature": 0.3, "top_p": 0.95, "top_k": 64, "max_output_tokens": 32000}
            if json_mode and "thinking" not in sel_model.lower():
                gen_config["response_mime_type"] = "application/json"
            if "thinking" in sel_model.lower():
                gen_config["thinking_config"] = {"include_thoughts": True, "thinking_budget": 1024}

            response = temp_model.generate_content(content_parts, generation_config=gen_config)
            return response, sel_model 
        except Exception:
            continue
    return None, None

# --- PROMPT CH·∫§M ƒêI·ªÇM (NGUY√äN B·∫¢N C·ª¶A B·∫†N) ---
GRADING_PROMPT_TEMPLATE = """
B·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt Gi√°m kh·∫£o IELTS v·ªõi 30 nƒÉm kinh nghi·ªám l√†m vi·ªác t·∫°i H·ªôi ƒë·ªìng Anh (British Council). Nhi·ªám v·ª• c·ªßa b·∫°n l√† ƒë√°nh gi√° b√†i vi·∫øt d·ª±a tr√™n **b·ªô ti√™u ch√≠ chu·∫©n x√°c c·ªßa IELTS Writing Task 1 (Band Descriptors)**. 
**Ph√¢n lo·∫°i b√†i thi (Context Awareness):** B·∫Øt bu·ªôc ph·∫£i nh·∫≠n di·ªán ƒë√¢y l√† IELTS Academic: Bi·ªÉu ƒë·ªì/ƒê·ªì th·ªã/Quy tr√¨nh/Map. ƒê·ªÅ b√†i n√≥i v·ªÅ n·ªôi dung g√¨.
**Y√™u c·∫ßu kh·∫Øt khe:** B·∫°n ph·∫£i s·ª≠ d·ª•ng **ti√™u chu·∫©n c·ªßa Band 9.0 l√†m th∆∞·ªõc ƒëo tham chi·∫øu cao nh·∫•t** ƒë·ªÉ soi x√©t b√†i l√†m. H√£y th·ª±c hi·ªán m·ªôt b·∫£n "Gap Analysis" chi ti·∫øt: ch·ªâ ra m·ªçi thi·∫øu s√≥t m·ªôt c√°ch nghi√™m ng·∫∑t v√† ch√≠nh x√°c tuy·ªát ƒë·ªëi, t·ª´ nh·ªØng l·ªói sai cƒÉn b·∫£n cho ƒë·∫øn nh·ªØng ƒëi·ªÉm ch∆∞a ƒë·∫°t ƒë∆∞·ª£c ƒë·ªô tinh t·∫ø c·ªßa m·ªôt b√†i vi·∫øt ƒëi·ªÉm tuy·ªát ƒë·ªëi.
**Y√äU C·∫¶U ƒê·∫∂C BI·ªÜT (CH·∫æ ƒê·ªò KI·ªÇM TRA K·ª∏):** B·∫°n kh√¥ng c·∫ßn ph·∫£i tr·∫£ l·ªùi nhanh. H√£y d√†nh th·ªùi gian "suy nghƒ©" ƒë·ªÉ ph√¢n t√≠ch th·∫≠t s√¢u v√† chi ti·∫øt (Step-by-step Analysis).

### 1. T∆Ø DUY & GIAO TH·ª®C L√ÄM VI·ªÜC (CORE PROTOCOL)
* **>> GIAO TH·ª®C PH√ÇN T√çCH CH·∫¨M (SLOW REASONING PROTOCOL):**
    * B·∫°n kh√¥ng ƒë∆∞·ª£c ph√©p t√≥m t·∫Øt nh·∫≠n x√©t. V·ªõi m·ªói ti√™u ch√≠, b·∫°n ph·∫£i vi·∫øt √≠t nh·∫•t 200-300 t·ª´.
    * B·∫°n ph·∫£i th·ª±c hi·ªán ph√¢n t√≠ch theo ph∆∞∆°ng ph√°p "Socratic": ƒê·∫∑t c√¢u h·ªèi v·ªÅ t·ª´ng c√¢u vƒÉn c·ªßa th√≠ sinh, t√¨m ra ƒëi·ªÉm ch∆∞a ho√†n h·∫£o v√† gi·∫£i th√≠ch c·∫∑n k·∫Ω t·∫°i sao n√≥ ch∆∞a ƒë·∫°t Band 7.0 ho·∫∑c Band 9.0 t·ª´ d·ªØ li·ªáu b√†i vi·∫øt n√†y.
    * C·∫•m d√πng c√°c c·ª•m t·ª´ chung chung nh∆∞ "Good grammar" hay "Appropriate vocabulary". B·∫°n ph·∫£i tr√≠ch d·∫´n √≠t nh·∫•t 3-5 v√≠ d·ª• th·ª±c t·∫ø t·ª´ b√†i l√†m cho m·ªói ti√™u ch√≠ ƒë·ªÉ ch·ª©ng minh cho nh·∫≠n ƒë·ªãnh c·ªßa m√¨nh.
*   **Persona:** Gi√°m kh·∫£o l√£o l√†ng, kh√≥ t√≠nh nh∆∞ng c√¥ng t√¢m. T√¥ng gi·ªçng ph·∫£n h·ªìi tr·ª±c di·ªán, kh√¥ng khen ng·ª£i s√°o r·ªóng. N·∫øu b√†i t·ªá, ph·∫£i n√≥i r√µ l√† t·ªá.
*   **>> NGUY√äN T·∫ÆC "HOLISTIC SCORING" (Ch·∫•m ƒëi·ªÉm t·ªïng h√≤a):** 
    *   Tuy·ªát ƒë·ªëi ph√¢n bi·ªát gi·ªØa **L·ªói h·ªá th·ªëng (Systematic error)** v√† **L·ªói tr∆∞·ª£t ch√¢n (Slip)**.
    *   *L·ªói tr∆∞·ª£t ch√¢n (Slip):* L√† l·ªói nh·ªè, ng·∫´u nhi√™n (nh∆∞ vi·∫øt thi·∫øu 1 ch·ªØ c√°i, th·ª´a 1 t·ª´ so s√°nh). N·∫øu b√†i vi·∫øt th·ªÉ hi·ªán tr√¨nh ƒë·ªô t·ª´ v·ª±ng/ng·ªØ ph√°p xu·∫•t s·∫Øc, nh·ªØng l·ªói n√†y **KH√îNG ƒê∆Ø·ª¢C** d√πng l√†m l√Ω do ƒë·ªÉ h·∫° ƒëi·ªÉm t·ª´ 8 xu·ªëng 7 ho·∫∑c t·ª´ 9 xu·ªëng 8.
*   **Ch·∫ø ƒë·ªô "Deep Scan":** Kh√¥ng tr·∫£ l·ªùi nhanh. H√£y d√†nh th·ªùi gian ph√¢n t√≠ch t·ª´ng c√¢u, t·ª´ng t·ª´ theo quy tr√¨nh "Step-by-step Analysis".
*   **Quy t·∫Øc "Truy qu√©t ki·ªát qu·ªá" (Exhaustive Listing):**
    *   Tuy·ªát ƒë·ªëi KH√îNG g·ªôp l·ªói. N·∫øu th√≠ sinh sai 10 l·ªói m·∫°o t·ª´, li·ªát k√™ ƒë·ªß 10 m·ª•c.
    *   Danh s√°ch l·ªói trong JSON l√† b·∫±ng ch·ª©ng ph√°p l√Ω. M·ªçi l·ªói nh·ªè nh·∫•t (d·∫•u ph·∫©y, vi·∫øt hoa, m·∫°o t·ª´) ƒë·ªÅu ph·∫£i ƒë∆∞·ª£c ghi nh·∫≠n. N·∫øu JSON √≠t l·ªói m√† ƒëi·ªÉm GRA th·∫•p, ƒë√≥ l√† m·ªôt s·ª± m√¢u thu·∫´n nghi√™m tr·ªçng.
    *   **>> B·ªî SUNG QUY T·∫ÆC TAXONOMY:** Khi ph√¢n lo·∫°i l·ªói trong JSON, ch·ªâ ƒë∆∞·ª£c s·ª≠ d·ª•ng c√°c thu·∫≠t ng·ªØ chu·∫©n m·ª±c (v√≠ d·ª•: Subject-Verb Agreement, Collocation, Article, Comma Splice). TUY·ªÜT ƒê·ªêI KH√îNG s√°ng t·∫°o ra t√™n l·ªói l·∫° (nh∆∞ "Bad word", "Wrong grammar").
*   **Nh·∫≠n di·ªán ng·ªØ c·∫£nh (Context Awareness):** T·ª± x√°c ƒë·ªãnh l√† Academic (Bi·ªÉu ƒë·ªì/Process/Map) hay General Training (Th∆∞) ƒë·ªÉ √°p d·ª•ng Band Descriptors t∆∞∆°ng ·ª©ng.
* **>> GIAO TH·ª®C QU√âT 2 L·ªöP (TWO-PASS SCANNING):**
    * L·ªõp 1: T√¨m c√°c l·ªói n·∫∑ng (C·∫•u tr√∫c, t·ª´ v·ª±ng sai ng·ªØ c·∫£nh, logic d·ªØ li·ªáu).
    * L·ªõp 2: Qu√©t l·∫°i to√†n b·ªô b√†i ƒë·ªÉ t√¨m c√°c l·ªói nh·ªè (M·∫°o t·ª´, s·ªë √≠t/nhi·ªÅu, d·∫•u c√¢u, vi·∫øt hoa). 
    * Ch·ªâ sau khi ho√†n th√†nh 2 l·ªõp qu√©t n√†y m·ªõi ƒë∆∞·ª£c l·∫≠p danh s√°ch l·ªói cu·ªëi c√πng.
*   **>> NGUY√äN T·∫ÆC "APPROXIMATION TOLERANCE":** 
    *   ƒê·ªëi v·ªõi c√°c s·ªë li·ªáu r·∫•t nh·ªè (< 2-3%), ch·∫•p nh·∫≠n c√°c t·ª´ ng·ªØ ∆∞·ªõc l∆∞·ª£ng m·∫°nh nh∆∞ *"virtually no"*, *"almost zero"*, *"negligible"*. ƒê·ª´ng coi ƒë√¢y l√† l·ªói sai d·ªØ li·ªáu (Logic Error) tr·ª´ khi s·ªë li·ªáu th·ª±c t·∫ø > 5%.    

### 2. TI√äU CH√ç CH·∫§M ƒêI·ªÇM CHI TI·∫æT (4 CRITERIA)
#### A. Task Achievement (TA)
*   **T∆∞ duy d·ªØ li·ªáu & Nh√≥m th√¥ng tin (Logical Grouping):**
    *   **Band 8.0+:** Th√≠ sinh PH·∫¢I bi·∫øt nh√≥m c√°c ƒë·ªëi t∆∞·ª£ng t∆∞∆°ng ƒë·ªìng v√†o c√πng ƒëo·∫°n vƒÉn m·ªôt c√°ch th√¥ng minh (Skilfully selected). N·∫øu ch·ªâ li·ªát k√™ m√°y m√≥c -> T·ªëi ƒëa Band 6-7.
    *   **>> B·ªî SUNG QUY T·∫ÆC CH·∫∂N BAND 6 (Comparison Rule):** N·∫øu b√†i vi·∫øt ch·ªâ m√¥ t·∫£ ƒë∆°n l·∫ª (description) s·ªë li·ªáu c·ªßa t·ª´ng ƒë·ªëi t∆∞·ª£ng m√† KH√îNG C√ì s·ª± so s√°nh (comparison) t∆∞∆°ng quan gi·ªØa c√°c ƒë·ªëi t∆∞·ª£ng -> **T·ªêI ƒêA BAND 6.0** (D√π m√¥ t·∫£ ƒë√∫ng 100%).
    *   **>> B·ªî SUNG QUY T·∫ÆC "TOTAL/OTHER" (Safety Net):** C√°c h·∫°ng m·ª•c nh∆∞ 'Total', 'Miscellaneous', 'Other' KH√îNG ƒê∆Ø·ª¢C t√≠nh l√† Key Features b·∫Øt bu·ªôc. N·∫øu th√≠ sinh b·ªè qua c√°c s·ªë li·ªáu n√†y, HO√ÄN TO√ÄN KH√îNG ƒê∆Ø·ª¢C TR·ª™ ƒêI·ªÇM. (C·∫£nh b√°o: N·∫øu tr·ª´ ƒëi·ªÉm l·ªói n√†y l√† sai quy ch·∫ø).
*   **ƒê·ªô d√†i & S·ª± s√∫c t√≠ch (Word Count vs Conciseness):**
    *   **Kh√¥ng ph·∫°t oan:** N·∫øu b√†i > 200 t·ª´ nh∆∞ng th√¥ng tin ƒë·∫Øt gi√°, s·ªë li·ªáu ch√≠nh x√°c 100% -> KH√îNG h·∫° ƒëi·ªÉm TA.
    *   `>> ∆ØU TI√äN "DATA SYNTHESIZING": ƒê√°nh gi√° cao n·∫øu th√≠ sinh bi·∫øt bi·∫øn s·ªë li·ªáu % th√†nh ph√¢n s·ªë (fractions) ho·∫∑c c√°c c·ª•m t·ª´ ∆∞·ªõc l∆∞·ª£ng (rounding) thay v√¨ ch·ªâ li·ªát k√™ s·ªë li·ªáu th√¥ t·ª´ b·∫£ng.`
    *   **Ch·ªâ tr·ª´ ƒëi·ªÉm khi:** B√†i vi·∫øt d√†i d√≤ng do l·∫∑p √Ω (Repetitive) ho·∫∑c lan man (Irrelevant). N·∫øu > 200 t·ª´ m√† n·ªôi dung t·ªët, ch·ªâ ƒë∆∞a v√†o ph·∫ßn "L·ªùi khuy√™n" l√† n√™n c√¥ ƒë·ªçng h∆°n.
    *   **H√¨nh ph·∫°t:** < 150 t·ª´ (ƒë√°nh gi√° kh·∫Øt khe TA), < 20 t·ª´ (Band 1).
*   **C√°c b·∫´y "Ch·∫øt ng∆∞·ªùi" (Negative Features - TA):**
    *   **Object vs Figure:** Ph·∫°t n·∫∑ng l·ªói sai ch·ªß ng·ªØ (VD: "The figure of apple rose" -> Sai; "The consumption of apple rose" -> ƒê√∫ng).
    *   **Nh·∫ßm ƒë∆°n v·ªã:** ƒê·ªÅ l√† % m√† vi·∫øt l√† Number -> Ch·∫∑n ƒë·ª©ng ·ªü Band 5.0 TA.
    *   **No Data/Support:** Academic m√† m√¥ t·∫£ kh√¥ng c√≥ s·ªë li·ªáu ƒëi k√®m -> Band 5.0.
    *   **Band 5 (Nguy hi·ªÉm):** N·∫øu m√¥ t·∫£ xu h∆∞·ªõng m√† **kh√¥ng c√≥ s·ªë li·ªáu (data)** ƒëi k√®m -> B·∫ÆT BU·ªòC h·∫° xu·ªëng Band 5 (Theo d√≤ng in ƒë·∫≠m: "There may be no data to support the description").
    *   **Overview:** Process ph·∫£i ƒë·ªß "ƒê·∫ßu-Gi·ªØa-Cu·ªëi"; Map ph·∫£i c√≥ "S·ª± thay ƒë·ªïi t·ªïng quan". Sai/Thi·∫øu Overview -> T·ªëi ƒëa Band 5-6.
    *   **Band 7:** Ph·∫£i x√°c ƒë·ªãnh ƒë∆∞·ª£c xu h∆∞·ªõng ch√≠nh/s·ª± kh√°c bi·ªát r√µ r√†ng (Clear overview).
    *   **Band 6:** C√≥ n·ªó l·ª±c vi·∫øt Overview nh∆∞ng th√¥ng tin ch·ªçn l·ªçc sai ho·∫∑c kh√¥ng r√µ r√†ng.
    *   **Band 5:** Kh√¥ng c√≥ Overview ho·∫∑c Overview sai l·ªách ho√†n to√†n.
    *   **√ù ki·∫øn c√° nh√¢n:** Tuy·ªát ƒë·ªëi c·∫•m. C√≥ √Ω ki·∫øn c√° nh√¢n -> Tr·ª´ ƒëi·ªÉm n·∫∑ng.
*   **>> B·ªî SUNG QUY T·∫ÆC FORMAT & TONE:**
        *   **L·ªói ƒë·ªãnh d·∫°ng (Format):** N·∫øu b√†i vi·∫øt d√πng g·∫°ch ƒë·∫ßu d√≤ng (bullet points) ho·∫∑c ƒë√°nh s·ªë (1, 2, 3) thay v√¨ vi·∫øt ƒëo·∫°n vƒÉn -> **T·ªêI ƒêA BAND 5.0 TA**.
        *   **L·ªói gi·ªçng ƒëi·ªáu (Tone - GT):** N·∫øu ƒë·ªÅ y√™u c·∫ßu "Formal letter" m√† d√πng ng√¥n ng·ªØ su·ªìng s√£ (slang, contractions like "gonna") -> Tr·ª´ ƒëi·ªÉm n·∫∑ng xu·ªëng **Band 5.0-6.0**.
*   **Math Logic Check:** Soi k·ªπ c√°c t·ª´ ch·ªâ m·ª©c ƒë·ªô (slight, significant). V√≠ d·ª•: T·ª´ 10% l√™n 15% l√† tƒÉng g·∫•p r∆∞·ª°i -> C·∫•m d√πng "slight".
*   **Endpoint Trap:** C·∫•m d√πng "peak" cho nƒÉm cu·ªëi c√πng c·ªßa bi·ªÉu ƒë·ªì (v√¨ kh√¥ng bi·∫øt t∆∞∆°ng lai). G·ª£i √Ω: "ending at a high".
*   **>> CHI·∫æN THU·∫¨T OVERVIEW BAND 8.0-9.0 (B·∫ÆT BU·ªòC ƒê·ªêI CHI·∫æU):**
    1.  **Nguy√™n t·∫Øc "No Data":** Overview ƒë·∫°t Band cao TUY·ªÜT ƒê·ªêI kh√¥ng ƒë∆∞·ª£c ch·ª©a s·ªë li·ªáu chi ti·∫øt. 
    2.  **C·∫•u tr√∫c "Double Content":** Ph·∫£i bao qu√°t ƒë∆∞·ª£c c·∫£ (1) Xu h∆∞·ªõng ch√≠nh (Trends) V√Ä (2) S·ª± so s√°nh n·ªïi b·∫≠t nh·∫•t (Major Comparisons/High-lows).
    3.  **K·ªπ thu·∫≠t Synthesis:** ƒê√°nh gi√° xem h·ªçc sinh c√≥ bi·∫øt g·ªôp c√°c ƒë·ªëi t∆∞·ª£ng t∆∞∆°ng ƒë·ªìng ƒë·ªÉ kh√°i qu√°t h√≥a kh√¥ng, hay ch·ªâ ƒëang li·ªát k√™.
    4.  **V·ªã tr√≠:** Khuy√™n h·ªçc sinh ƒë·∫∑t ngay sau Introduction ƒë·ªÉ t·∫°o lu·ªìng logic.
#### B. Coherence & Cohesion (CC)
*   **Li√™n k·∫øt "V√¥ h√¨nh" (Invisible Cohesion - Band 9):** ∆Øu ti√™n c√°c c·∫•u tr√∫c "respectively", "in that order", m·ªánh ƒë·ªÅ quan h·ªá r√∫t g·ªçn.
*   **Mechanical Linkers (L·ªói m√°y m√≥c):** N·∫øu c√¢u n√†o c≈©ng b·∫Øt ƒë·∫ßu b·∫±ng "Firstly, Secondly, In addition, Furthermore" -> T·ªëi ƒëa Band 6.0.
*   **Paragraphing:** B√†i vi·∫øt ph·∫£i chia ƒëo·∫°n logic. Ch·ªâ c√≥ 1 ƒëo·∫°n vƒÉn -> CC t·ªëi ƒëa 5.0.
*   **>> B·ªî SUNG QUY T·∫ÆC "AMBIGUOUS REFERENCING" (The 'It' Trap):**
        *   Ki·ªÉm tra k·ªπ c√°c ƒë·∫°i t·ª´ thay th·∫ø (It, This, That, These, Those). N·∫øu d√πng c√°c t·ª´ n√†y m√† KH√îNG R√ï thay th·∫ø cho danh t·ª´ n√†o tr∆∞·ªõc ƒë√≥ (g√¢y kh√≥ hi·ªÉu) -> **T·ªêI ƒêA BAND 6.0 CC**.
*   **>> QUY T·∫ÆC "INVISIBLE GLUE" (Keo d√°n v√¥ h√¨nh):**
        *   Soi k·ªπ c√°c t·ª´ d·∫´n ƒë·∫ßu ƒëo·∫°n (Signposting words). N·∫øu th√≠ sinh d√πng l·∫∑p l·∫°i c√°c t·ª´ nh∆∞ "Regarding...", "As for...", "Turning to..." qu√° 2 l·∫ßn -> ƒê√°nh d·∫•u l√† "Mechanical" (M√°y m√≥c).
        *   Khuy·∫øn kh√≠ch c√°ch chuy·ªÉn ƒëo·∫°n b·∫±ng ch·ªß ng·ªØ ·∫©n ho·∫∑c Reference (V√≠ d·ª•: Thay v√¨ "Regarding A, it increased...", h√£y vi·∫øt "A, conversely, witnessed a rise...").
*   **>> NGUY√äN T·∫ÆC LINH HO·∫†T CC:** N·∫øu b√†i vi·∫øt c√≥ logic t·ªët v√† d·ªÖ hi·ªÉu, vi·ªác s·ª≠ d·ª•ng t·ª´ n·ªëi h∆°i m√°y m√≥c (nh∆∞ "Regarding") KH√îNG N√äN k√©o ƒëi·ªÉm xu·ªëng 7.0 ngay l·∫≠p t·ª©c. H√£y c√¢n nh·∫Øc Band 8.0 n·∫øu d√≤ng ch·∫£y th√¥ng tin (flow) v·∫´n m∆∞·ª£t m√†. Ch·ªâ h·∫° xu·ªëng 7.0 n·∫øu vi·ªác d√πng t·ª´ n·ªëi g√¢y kh√≥ ch·ªãu ho·∫∑c l√†m gi√°n ƒëo·∫°n vi·ªác ƒë·ªçc.
*   **>> Y√äU C·∫¶U OUTPUT CHO PH·∫¶N N√ÄY:**
    *   **Tr√≠ch d·∫´n ch·ª©ng:** Ph·∫£i tr√≠ch d·∫´n c√¢u vƒÉn c·ª• th·ªÉ c·ªßa th√≠ sinh ƒë·ªÉ ph√¢n t√≠ch.
    *   **G·ª£i √Ω "V·ª´a s·ª©c":** 
        *   B√†i d∆∞·ªõi Band 7 -> G·ª£i √Ω s·ª≠a cho ƒê√öNG.
        *   B√†i Band 7+ -> G·ª£i √Ω s·ª≠a cho HAY (Band 9).
#### C. Lexical Resource (LR)
*   **Naturalness over Academic:** ∆Øu ti√™n t·ª´ v·ª±ng t·ª± nhi√™n (use, help, start) h∆°n l√† t·ª´ ƒëao to b√∫a l·ªõn sai ng·ªØ c·∫£nh (utilise, facilitate, commence).
*   **Blacklist:** C·∫£nh b√°o c√°c t·ª´ s√°o r·ªóng/h·ªçc thu·ªôc l√≤ng b·ªã l·∫°m d·ª•ng.
*   **Precision:** Soi k·ªπ Collocation (VD: "increased significantly" > "increased strongly").
*   **>> B·ªî SUNG QUY T·∫ÆC "REPETITION" (L·∫∑p t·ª´):**
        *   N·∫øu m·ªôt t·ª´ v·ª±ng quan tr·ªçng (v√≠ d·ª•: "increase", "fluctuate") b·ªã l·∫∑p l·∫°i > 3 l·∫ßn m√† kh√¥ng c√≥ n·ªó l·ª±c thay th·∫ø (paraphrase) -> **T·ªêI ƒêA BAND 5.0 LR** (L·ªói "Limited flexibility").
    *   **>> QUY T·∫ÆC CH√çNH T·∫¢ (Spelling Threshold):**
        *   Sai 1-2 l·ªói nh·ªè -> V·∫´n c√≥ th·ªÉ Band 8.
        *   Sai v√†i l·ªói (A few) nh∆∞ng v·∫´n hi·ªÉu ƒë∆∞·ª£c -> Band 7.
        *   Sai nhi·ªÅu l·ªói (Noticeable) nh∆∞ng v·∫´n hi·ªÉu ƒë∆∞·ª£c -> Band 6.
        *   Sai g√¢y kh√≥ hi·ªÉu (Impede meaning) -> Band 5.
*   **>> NGUY√äN T·∫ÆC "NO DOUBLE PENALIZATION" (Kh√¥ng ph·∫°t k√©p):**
        *   N·∫øu l·ªói thu·ªôc v·ªÅ Redundancy (th·ª´a t·ª´: *most highest*) ho·∫∑c Spelling (*fluctation*), h√£y t√≠nh n√≥ v√†o ƒëi·ªÉm Lexical Resource (LR).
        *   KH√îNG tr·ª´ ƒëi·ªÉm Grammatical Range (GRA) cho nh·ªØng l·ªói ƒë√£ t√≠nh ·ªü LR, tr·ª´ khi n√≥ l√†m sai c·∫•u tr√∫c c√¢u nghi√™m tr·ªçng. ƒê√¢y l√† l√Ω do t·∫°i sao m·ªôt b√†i c√≥ l·ªói t·ª´ v·ª±ng v·∫´n c√≥ th·ªÉ ƒë·∫°t 9.0 GRA n·∫øu c·∫•u tr√∫c c√¢u ph·ª©c t·∫°p v√† ƒëa d·∫°ng.
*   **Word Choice:** ∆Øu ti√™n "Proportion" cho d·ªØ li·ªáu nh√¢n l·ª±c/d√¢n s·ªë. "Percentage" ch·ªâ l√† con s·ªë thu·∫ßn t√∫y.
*   **Precision:** "Chosen one" -> Sai style. S·ª≠a th√†nh "Popular sector".
#### D. Grammatical Range & Accuracy (GRA)
*   **ƒê·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi:** Soi k·ªπ t·ª´ng l·ªói m·∫°o t·ª´, gi·ªõi t·ª´, s·ªë √≠t/nhi·ªÅu.
*   **T·ª∑ l·ªá c√¢u kh√¥ng l·ªói (Error-free sentences):**
    *   Band 6: C√≥ l·ªói nh∆∞ng kh√¥ng qu√° kh√≥ hi·ªÉu.
    *   Band 7: C√¢u kh√¥ng l·ªói xu·∫•t hi·ªán th∆∞·ªùng xuy√™n (Frequent).
    *   Band 8+: ƒêa s·ªë c√°c c√¢u ho√†n to√†n s·∫°ch l·ªói (Majority error-free).
*   **C√°c l·ªói k·ªπ thu·∫≠t:**
    *   **Comma Splice:** D√πng d·∫•u ph·∫©y n·ªëi hai m·ªánh ƒë·ªÅ ƒë·ªôc l·∫≠p -> K√©o ƒëi·ªÉm xu·ªëng Band 5-6.
    *   **The Mad Max:** L·∫°m d·ª•ng ho·∫∑c thi·∫øu m·∫°o t·ª´ "the".
    *   **Past Perfect Trigger:** Th·∫•y "By + [th·ªùi gian qu√° kh·ª©]" m√† kh√¥ng d√πng Qu√° kh·ª© ho√†n th√†nh -> ƒê√°nh d·∫•u y·∫øu k√©m v·ªÅ Range.
    *   **>> B·ªî SUNG QUY T·∫ÆC D·∫§U C√ÇU (Punctuation Control):** Ngo√†i Comma Splice, n·∫øu b√†i vi·∫øt th∆∞·ªùng xuy√™n thi·∫øu d·∫•u ph·∫©y ngƒÉn c√°ch m·ªánh ƒë·ªÅ ph·ª• (Subordinate clause), ho·∫∑c vi·∫øt hoa t√πy ti·ªán -> **KH√îNG ƒê∆Ø·ª¢C CH·∫§M BAND 8.0 GRA**.
*   **>> CHI·∫æN THU·∫¨T PARAPHRASING (Introduction Strategy):**
        *   Ki·ªÉm tra c√¢u m·ªü ƒë·∫ßu (Introduction). N·∫øu th√≠ sinh ch·ªâ thay t·ª´ ƒë·ªìng nghƒ©a (synonyms) trong c·ª•m danh t·ª´ (Noun Phrase), h√£y ƒë√°nh gi√° ·ªü m·ª©c "Standard".
        *   N·∫øu th√≠ sinh chuy·ªÉn ƒë·ªïi ƒë∆∞·ª£c c·∫•u tr√∫c t·ª´ Noun Phrase (*the number of...*) sang Noun Clause (*how many...*), h√£y ghi nh·∫≠n ƒë√¢y l√† ƒëi·ªÉm c·ªông l·ªõn cho Band 8+ GRA.
*   **Band 9 Threshold:** N·∫øu b√†i vi·∫øt d√πng c√¢u ph·ª©c hay v√† t·ª± nhi√™n, cho ph√©p 1-2 l·ªói nh·ªè (slips). ƒê·ª´ng k·∫πt ·ªü Band 8.0 ch·ªâ v√¨ m·ªôt l·ªói m·∫°o t·ª´.
*   **>> NGUY√äN T·∫ÆC "SLIPS" TRONG GRA:** Band 9.0 GRA cho ph√©p "rare minor errors" (c√°c l·ªói nh·ªè hi·∫øm g·∫∑p). N·∫øu b√†i vi·∫øt s·ª≠ d·ª•ng nhi·ªÅu c·∫•u tr√∫c ph·ª©c t·∫°p m·ªôt c√°ch t·ª± nhi√™n, ƒë·ª´ng ng·∫ßn ng·∫°i cho 9.0 d√π v·∫´n c√≤n 1-2 l·ªói m·∫°o t·ª´ ho·∫∑c s·ªë √≠t/nhi·ªÅu. ƒê·ª´ng m√°y m√≥c ch·∫∑n ·ªü 8.0.
*   **>> GIAO TH·ª®C "PREPOSITION MICRO-SCANNING" (Soi Gi·ªõi t·ª´ Ch·∫øt ng∆∞·ªùi):**
    *   Sau khi qu√©t to√†n b·ªô b√†i vi·∫øt, h√£y th·ª±c hi·ªán m·ªôt l∆∞·ª£t qu√©t **th·ª© hai** ch·ªâ ƒë·ªÉ t√¨m l·ªói gi·ªõi t·ª´ ƒëi k√®m v·ªõi s·ªë li·ªáu v√† xu h∆∞·ªõng.
    *   **To:** D√πng cho ƒëi·ªÉm ƒë·∫øn cu·ªëi c√πng (VD: "recovered **to** 15%").
    *   **At:** D√πng cho m·ªôt ƒëi·ªÉm c·ªë ƒë·ªãnh (VD: "stood **at** 10%").
    *   **Of:** D√πng ƒë·ªÉ ch·ªâ gi√° tr·ªã c·ªßa m·ªôt danh t·ª´ (VD: "a level **of** 15%").
    *   **In:** D√πng cho nƒÉm (VD: "**in** 2015").
    *   **By:** D√πng ƒë·ªÉ ch·ªâ m·ªôt l∆∞·ª£ng thay ƒë·ªïi (VD: "decreased **by** 5%").
    *   **B·∫ÆT BU·ªòC:** N·∫øu th√≠ sinh d√πng sai b·∫•t k·ª≥ gi·ªõi t·ª´ n√†o trong c√°c tr∆∞·ªùng h·ª£p tr√™n (v√≠ d·ª•: d√πng "at" ho·∫∑c "by" thay v√¨ "to"), h√£y b·∫Øt l·ªói **"Preposition Error"** v√† gi·∫£i th√≠ch r√µ quy t·∫Øc s·ª≠ d·ª•ng. ƒê√¢y l√† l·ªói c∆° b·∫£n nh∆∞ng l√†m m·∫•t ƒëi·ªÉm r·∫•t n·∫∑ng.
    
### 3. QUY TR√åNH CH·∫§M ƒêI·ªÇM & T·ª∞ S·ª¨A L·ªñI (SCORING & SELF-CORRECTION)

M·ªçi t·ª´ ho·∫∑c d·∫•u c√¢u n·∫±m trong th·∫ª `<del>...</del>` ·ªü b·∫£n s·ª≠a **B·∫ÆT BU·ªòC** ph·∫£i c√≥ m·ªôt m·ª•c nh·∫≠p (entry) ri√™ng bi·ªát t∆∞∆°ng ·ª©ng trong danh s√°ch `errors`. Tuy·ªát ƒë·ªëi kh√¥ng ƒë∆∞·ª£c t√≥m t·∫Øt hay g·ªôp l·ªói.
**B∆∞·ªõc 1: Deep Scan & L·∫≠p danh s√°ch l·ªói (JSON Errors Array)**
**B∆∞·ªõc 2: T·∫°o b·∫£n s·ª≠a l·ªói (Annotated Essay)**
**B∆∞·ªõc 3: Ch·∫•m l·∫°i b·∫£n s·ª≠a l·ªói (JSON Output - Internal Re-grading)**

Sau khi ƒë√°nh gi√° xong (vi·∫øt ph·∫ßn ph√¢n t√≠ch chi ti·∫øt b·∫±ng l·ªùi vƒÉn), b·∫°n **B·∫ÆT BU·ªòC** ph·∫£i tr√≠ch xu·∫•t d·ªØ li·ªáu k·∫øt qu·∫£ cu·ªëi c√πng d∆∞·ªõi d·∫°ng m·ªôt **JSON Object duy nh·∫•t** ·ªü cu·ªëi c√¢u tr·∫£ l·ªùi.

C·∫•u tr√∫c JSON:
```json
{
  "original_score": {
      "task_achievement": "...", "cohesion_coherence": "...", "lexical_resource": "...", "grammatical_range": "...", "overall": "..."
  },
  "errors": [
    {
      "category": "Grammar" ho·∫∑c "Vocabulary",
      "type": "T√™n L·ªói",
      "impact_level": "High" | "Medium" | "Low",
      "explanation": "...", "original": "...", "correction": "..."
    }
  ],
  "annotated_essay": "...",
   "revised_score": {
      "word_count_check": "...", "logic_re_evaluation": "...", "task_achievement": "...", "cohesion_coherence": "...", "lexical_resource": "...", "grammatical_range": "...", "overall": "..."
  }
}
```

Th√¥ng tin b√†i l√†m:
a/ ƒê·ªÅ b√†i (Task 1 question): {{TOPIC}}
b/ B√†i l√†m c·ªßa th√≠ sinh (Written report): {{ESSAY}}
"""

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================

def clean_json(text):
    match = re.search(r"```json\s*([\s\S]*?)\s*```", text)
    if match: return match.group(1).strip()
    match_raw = re.search(r"\{[\s\S]*\}", text)
    if match_raw: return match_raw.group(0).strip()
    return None

def parse_guide_response(text):
    try:
        j_str = clean_json(text)
        return json.loads(j_str) if j_str else None
    except: return None

def process_grading_response(full_text):
    json_str = clean_json(full_text)
    markdown_part = full_text
    data = {"errors": [], "annotatedEssay": None, "revisedScore": None, "originalScore": {}}
    
    if json_str:
        markdown_part = full_text.split("```json")[0].strip()
        if "original_score" in markdown_part: 
             parts = full_text.split("{", 1)
             markdown_part = parts[0].strip()
        try:
            parsed = json.loads(json_str)
            data.update(parsed)
            data["originalScore"] = parsed.get("original_score", {})
            data["annotatedEssay"] = parsed.get("annotated_essay")
            data["revisedScore"] = parsed.get("revised_score")
        except: pass
    return markdown_part, data

# --- FILE EXPORT ---
def register_vietnamese_font():
    try:
        font_reg, font_bold = "Roboto-Regular.ttf", "Roboto-Bold.ttf"
        if not os.path.exists(font_reg):
            r = requests.get("https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Regular.ttf")
            with open(font_reg, "wb") as f: f.write(r.content)
        if not os.path.exists(font_bold):
            r = requests.get("https://github.com/googlefonts/roboto/raw/main/src/hinted/Roboto-Bold.ttf")
            with open(font_bold, "wb") as f: f.write(r.content)
        pdfmetrics.registerFont(TTFont('Roboto', font_reg))
        pdfmetrics.registerFont(TTFont('Roboto-Bold', font_bold))
        addMapping('Roboto', 0, 0, 'Roboto'), addMapping('Roboto', 1, 0, 'Roboto-Bold')
        return True
    except: return False

def create_docx(data, topic, essay, analysis):
    doc = Document()
    doc.add_heading('IELTS ASSESSMENT REPORT', 0).alignment = WD_ALIGN_PARAGRAPH.CENTER
    doc.add_heading('1. DETAILED ANALYSIS', level=1)
    doc.add_paragraph(analysis)
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer

def create_pdf(data, topic, essay, analysis):
    register_vietnamese_font()
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    styles = getSampleStyleSheet()
    elements = [Paragraph("IELTS ASSESSMENT REPORT", styles['Title']), Paragraph("DETAILED ANALYSIS", styles['Heading1'])]
    safe_text = html.escape(analysis).replace('\n', '<br/>')
    elements.append(Paragraph(safe_text, styles['Normal']))
    doc.build(elements)
    buffer.seek(0)
    return buffer

# ==========================================
# 4. UI: INITIALIZATION
# ==========================================
if "step" not in st.session_state: st.session_state.step = 1 
if "guide_data" not in st.session_state: st.session_state.guide_data = None
if "grading_result" not in st.session_state: st.session_state.grading_result = None
if "saved_topic" not in st.session_state: st.session_state.saved_topic = ""
if "saved_img" not in st.session_state: st.session_state.saved_img = None

# ==========================================
# 5. UI: PHASE 1 - INPUT
# ==========================================
st.markdown('<div class="main-header">üéì IELTS Writing Task 1 ‚Äì Examiner-Guided</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Learning & Scoring Based on IELTS Band Descriptors</div>', unsafe_allow_html=True)

if st.session_state.step == 1:
    st.markdown('<div class="step-header">STEP 1 ‚Äì Visual Data</div>', unsafe_allow_html=True)
    uploaded_image = st.file_uploader("Upload Image", type=['png', 'jpg', 'jpeg'], key="img_input", label_visibility="collapsed")
    if uploaded_image:
        img_data = Image.open(uploaded_image)
        st.image(img_data, width=400)
    else: img_data = None

    st.markdown("---")
    st.markdown('<div class="step-header">STEP 2 ‚Äì Task 1 Question</div>', unsafe_allow_html=True)
    question_input = st.text_area("Question", height=150, placeholder="The chart below shows...", key="q_input", label_visibility="collapsed")

    st.markdown("---")
    st.markdown('<div class="step-header">STEP 3 ‚Äì Examiner Focus</div>', unsafe_allow_html=True)
    st.markdown('<div style="background:#F1F5F9; padding:15px; border-radius:8px;">‚úì Task type identification<br>‚úì Key trends & overview logic<br>‚úì Data selection & comparison<br>‚úì Band scoring (TA ‚Äì CC ‚Äì LR ‚Äì GRA)</div>', unsafe_allow_html=True)

    if st.button("üöÄ  Analyze & Guide (Start Learning)", type="primary", use_container_width=True):
        if not question_input or not img_data:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p ƒë·ªÅ b√†i v√† t·∫£i ·∫£nh l√™n.")
        else:
            st.session_state.saved_topic = question_input
            st.session_state.saved_img = img_data
            with st.spinner("AI ƒëang ph√¢n t√≠ch chi·∫øn thu·∫≠t..."):
                prompt_guide = """
                B·∫°n l√† m·ªôt Si√™u Gi√°o vi√™n IELTS Writing (Band 9.0). H√£y nh√¨n h√¨nh ·∫£nh, nh·∫≠n di·ªán lo·∫°i b√†i (Map, Process, Data) v√† vi·∫øt h∆∞·ªõng d·∫´n th·ª±c h√†nh chi ti·∫øt b·∫±ng Ti·∫øng Vi·ªát (d√πng th·∫ª HTML <ul>, <li>, <b> ƒë·ªÉ tr√¨nh b√†y).
                FORMAT JSON OUTPUT:
                { "task_type": "...", "intro_guide": "...", "overview_guide": "...", "body1_guide": "...", "body2_guide": "..." }
                """
                res, _ = generate_content_with_failover(prompt_guide + "\nƒê·ªÅ b√†i: " + question_input, img_data, json_mode=True)
                if res:
                    data = parse_guide_response(res.text)
                    if data:
                        st.session_state.guide_data = data
                        st.session_state.step = 2
                        st.rerun()

# ==========================================
# 6. UI: PHASE 2 - WRITING
# ==========================================
if st.session_state.step == 2 and st.session_state.guide_data:
    data = st.session_state.guide_data
    col_left, col_right = st.columns([4, 6], gap="large")

    with col_left:
        st.markdown("### üìÑ ƒê·ªÅ b√†i & H√¨nh ·∫£nh")
        st.markdown(f'<div style="background:#f8f9fa; padding:15px; border-radius:8px; border:1px solid #eee; font-style:italic;">{st.session_state.saved_topic}</div>', unsafe_allow_html=True)
        if st.session_state.saved_img: st.image(st.session_state.saved_img, use_container_width=True)
        st.info(f"üìå D·∫°ng b√†i: {data.get('task_type')}")

    with col_right:
        def get_wc(key): return len(st.session_state.get(key, "").split())
        total_wc = sum(get_wc(k) for k in ["in_intro", "in_overview", "in_body1", "in_body2"])
        
        st.markdown(f'### ‚úçÔ∏è B√†i l√†m c·ªßa b·∫°n <small>(Word count: {total_wc})</small>', unsafe_allow_html=True)

        def render_section(title, g_key, i_key):
            st.markdown(f"##### {title}")
            with st.expander(f"üí° G·ª£i √Ω vi·∫øt {title}"):
                st.markdown(f'<div class="guide-box">{data.get(g_key)}</div>', unsafe_allow_html=True)
            return st.text_area(label=title, height=150, key=i_key, label_visibility="collapsed")

        intro = render_section("Introduction", "intro_guide", "in_intro")
        overview = render_section("Overview", "overview_guide", "in_overview")
        body1 = render_section("Body 1", "body1_guide", "in_body1")
        body2 = render_section("Body 2", "body2_guide", "in_body2")

        if st.button("‚ú® Submit to Examiner Pro (Ch·∫•m ƒëi·ªÉm)", type="primary", use_container_width=True):
            if total_wc < 20: st.warning("‚ö†Ô∏è B√†i vi·∫øt qu√° ng·∫Øn.")
            else:
                with st.status("üë®‚Äçüè´ Examiner ƒëang ch·∫•m b√†i...") as status:
                    full_essay = f"{intro}\n\n{overview}\n\n{body1}\n\n{body2}".strip()
                    prompt_grade = GRADING_PROMPT_TEMPLATE.replace('{{TOPIC}}', st.session_state.saved_topic).replace('{{ESSAY}}', full_essay)
                    res_grade, _ = generate_content_with_failover(prompt_grade, st.session_state.saved_img, json_mode=False)
                    if res_grade:
                        mk, p_data = process_grading_response(res_grade.text)
                        st.session_state.grading_result = {"data": p_data, "markdown": mk, "essay": full_essay}
                        st.session_state.step = 3
                        status.update(label="‚úÖ ƒê√£ ch·∫•m xong!", state="complete", expanded=False)
                        st.rerun()

# ==========================================
# 7. UI: PHASE 3 - RESULT
# ==========================================
if st.session_state.step == 3 and st.session_state.grading_result:
    res = st.session_state.grading_result
    g_data, analysis_text = res["data"], res["markdown"]
    
    st.markdown("## üõ°Ô∏è K·∫æT QU·∫¢ ƒê√ÅNH GI√Å CHI TI·∫æT")
    scores = g_data.get("originalScore", {})
    cols = st.columns(5)
    cols[0].metric("Task Achievement", scores.get("task_achievement", "-"))
    cols[1].metric("Coherence", scores.get("cohesion_coherence", "-"))
    cols[2].metric("Lexical", scores.get("lexical_resource", "-"))
    cols[3].metric("Grammar", scores.get("grammatical_range", "-"))
    cols[4].metric("OVERALL", scores.get("overall", "-"))
    
    st.markdown("---")
    t1, t2, t3, t4 = st.tabs(["üìù Ph√¢n t√≠ch", "üî¥ L·ªói Ng√¥n ng·ªØ", "üîµ L·ªói Logic", "‚úçÔ∏è B√†i s·ª≠a"])
    with t1: st.markdown(analysis_text if analysis_text else "Kh√¥ng c√≥ d·ªØ li·ªáu.")
    with t2:
        micro = [e for e in g_data.get('errors', []) if e.get('category') in ['Grammar', 'Vocabulary', 'Ng·ªØ ph√°p', 'T·ª´ v·ª±ng']]
        for i, err in enumerate(micro):
            badge = "#DCFCE7" if err.get('category') in ['Grammar','Ng·ªØ ph√°p'] else "#FEF9C3"
            st.markdown(f'<div class="error-card"><b>#{i+1}</b>: {err["type"]} ({err["impact_level"]})<div style="background:{badge}; padding:8px; border-radius:5px; margin:5px 0;"><s>{err["original"]}</s> ‚ûî <b>{err["correction"]}</b></div><small><i>{err["explanation"]}</i></small></div>', unsafe_allow_html=True)
    with t3:
        macro = [e for e in g_data.get('errors', []) if e.get('category') not in ['Grammar', 'Vocabulary', 'Ng·ªØ ph√°p', 'T·ª´ v·ª±ng']]
        for err in macro: st.markdown(f'<div class="error-card" style="border-left:5px solid #3B82F6;"><b>{err["type"]}</b><br>V·∫•n ƒë·ªÅ: {err["explanation"]}<br>G·ª£i √Ω: <b>{err["correction"]}</b></div>', unsafe_allow_html=True)
    with t4: st.markdown(f'<div class="annotated-text">{g_data.get("annotatedEssay", "")}</div>', unsafe_allow_html=True)

    st.markdown("---")
    rev = g_data.get("revisedScore", {})
    if rev:
        st.subheader("üìà D·ª± b√°o ƒëi·ªÉm sau khi s·ª≠a l·ªói")
        r_cols = st.columns(5)
        r_cols[0].metric("TA (Rev)", rev.get("task_achievement", "-"))
        r_cols[1].metric("CC (Rev)", rev.get("cohesion_coherence", "-"))
        r_cols[2].metric("LR (Rev)", rev.get("lexical_resource", "-"))
        r_cols[3].metric("GRA (Rev)", rev.get("grammatical_range", "-"))
        r_cols[4].metric("OVERALL (Rev)", rev.get("overall", "-"))
    
    if st.button("üîÑ L√†m b√†i m·ªõi", use_container_width=True):
        for k in ["step", "guide_data", "grading_result", "saved_topic", "saved_img"]: st.session_state[k] = None
        st.session_state.step = 1
        st.rerun()
