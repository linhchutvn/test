import streamlit as st
import google.generativeai as genai
from PIL import Image
import random
import json
import re

# --- C·∫§U H√åNH TRANG ---
st.set_page_config(page_title="IELTS Task 1 Intelligent Tutor", layout="wide")

# CSS ƒë·ªÉ giao di·ªán gi·ªëng m·∫´u (Khung x√°m, √¥ nh·∫≠p li·ªáu)
st.markdown("""
<style>
    .guide-box {
        background-color: #f8f9fa;
        border-left: 5px solid #ff4b4b;
        padding: 15px;
        border-radius: 5px;
        margin-bottom: 10px;
        color: #31333F;
    }
    .guide-title {
        font-weight: bold;
        margin-bottom: 5px;
        color: #ff4b4b;
    }
    .stTextArea textarea {
        font-size: 16px;
    }
</style>
""", unsafe_allow_html=True)

# --- LOGIC K·∫æT N·ªêI AI (C·ª¶A B·∫†N) ---
# L·∫•y Key t·ª´ secrets
try:
    ALL_KEYS = st.secrets["GEMINI_API_KEYS"]
except Exception:
    st.error("Ch∆∞a c·∫•u h√¨nh secrets.toml ho·∫∑c thi·∫øu GEMINI_API_KEYS")
    st.stop()

def generate_content_with_failover(prompt, image=None):
    """H√†m th√¥ng minh t·ª± ƒë·ªông d√≤ t√¨m Model t·ªët nh·∫•t c√≥ s·∫µn l∆∞·ª£t d√πng"""
    keys_to_try = list(ALL_KEYS)
    random.shuffle(keys_to_try) 
    
    # DANH S√ÅCH ∆ØU TI√äN
    model_priority = [
        "gemini-2.0-flash-thinking-preview-01-21",
        "gemini-2.5-flash",
        "gemini-2.0-flash",
        "gemini-1.5-pro", 
        "gemini-1.5-flash"
    ]
    
    last_error = ""
    for index, current_key in enumerate(keys_to_try): 
        try:
            genai.configure(api_key=current_key)
            
            # L·∫•y danh s√°ch model
            available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            
            # T√¨m model t·ªët nh·∫•t
            sel_model = None
            for target in model_priority:
                if any(target in m_name for m_name in available_models):
                    sel_model = target
                    break
            
            if not sel_model:
                sel_model = "gemini-1.5-flash" 

            # Hi·ªÉn th·ªã k·∫øt n·ªëi (Debug)
            masked_key = f"****{current_key[-4:]}"
            with st.expander("üîå Tr·∫°ng th√°i k·∫øt n·ªëi AI", expanded=False):
                st.write(f"**Model:** `{sel_model}`")
                st.write(f"**Key:** `{masked_key}` (Key #{index + 1})")

            # Kh·ªüi t·∫°o model
            temp_model = genai.GenerativeModel(model_name=sel_model)
            
            content_parts = [prompt]
            if image:
                content_parts.append(image)
                
            gen_config = {
                "temperature": 0.4,       
                "top_p": 0.95,           
                "top_k": 64,             
                "max_output_tokens": 8192,
                "response_mime_type": "application/json" # √âp ki·ªÉu tr·∫£ v·ªÅ JSON ƒë·ªÉ d·ªÖ x·ª≠ l√Ω
            }

            # Config cho Thinking model (n·∫øu c√≥)
            if "thinking" in sel_model.lower():
                # Thinking model hi·ªán ch∆∞a h·ªó tr·ª£ √©p ki·ªÉu JSON qua MIME type ch·∫∑t ch·∫Ω ·ªü m·ªôt s·ªë version,
                # n√™n ta b·ªè mime_type n·∫øu l√† thinking ƒë·ªÉ tr√°nh l·ªói, v√† x·ª≠ l√Ω chu·ªói sau.
                del gen_config["response_mime_type"]
                gen_config["thinking_config"] = {"include_thoughts": False, "thinking_budget": 1024}

            response = temp_model.generate_content(
                content_parts,
                generation_config=gen_config
            )
            
            return response, sel_model 
            
        except Exception as e:
            last_error = str(e)
            if "429" in last_error or "quota" in last_error.lower():
                continue 
            else:
                # L·ªói kh√°c (400, 500) th√¨ break lu√¥n
                break
                
    st.error(f"‚ùå K·∫øt n·ªëi th·∫•t b·∫°i. L·ªói: {last_error}")
    return None, None

# --- X·ª¨ L√ù K·∫æT QU·∫¢ T·ª™ AI ---
def parse_ai_response(response_text):
    """L√†m s·∫°ch v√† chuy·ªÉn ƒë·ªïi text AI tr·∫£ v·ªÅ th√†nh Dictionary"""
    try:
        # X√≥a c√°c k√Ω t·ª± markdown json n·∫øu c√≥
        clean_text = re.sub(r'```json\n|```', '', response_text).strip()
        data = json.loads(clean_text)
        return data
    except json.JSONDecodeError:
        st.error("AI tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng d·ªØ li·ªáu kh√¥ng ƒë√∫ng. Vui l√≤ng th·ª≠ l·∫°i.")
        return None

# --- GIAO DI·ªÜN CH√çNH ---

st.title("‚úçÔ∏è IELTS Writing Task 1 Simulator")
st.caption("Nh·∫≠p ƒë·ªÅ b√†i, t·∫£i ·∫£nh v√† nh·∫≠n h∆∞·ªõng d·∫´n chi ti·∫øt t·ª´ AI ƒë·ªÉ th·ª±c h√†nh.")

col_input, col_img = st.columns([1, 1])

with col_input:
    st.subheader("1. ƒê·ªÅ b√†i")
    question_text = st.text_area("Nh·∫≠p c√¢u h·ªèi (Question Prompt):", height=200, placeholder="The chart below shows...")

with col_img:
    st.subheader("2. H√¨nh ·∫£nh")
    uploaded_file = st.file_uploader("Upload ·∫£nh bi·ªÉu ƒë·ªì/b·∫£n ƒë·ªì", type=['png', 'jpg', 'jpeg'])
    img_data = None
    if uploaded_file:
        img_data = Image.open(uploaded_file)
        st.image(img_data, caption="ƒê·ªÅ b√†i", use_container_width=True)

# Kh·ªüi t·∫°o session state
if "guide_data" not in st.session_state:
    st.session_state.guide_data = None

# N√∫t Action
if st.button("üöÄ H∆∞·ªõng D·∫´n & L·∫≠p D√†n √ù", type="primary"):
    if not question_text and not img_data:
        st.warning("Vui l√≤ng nh·∫≠p √≠t nh·∫•t c√¢u h·ªèi ho·∫∑c h√¨nh ·∫£nh.")
    else:
        with st.spinner("AI ƒëang ph√¢n t√≠ch bi·ªÉu ƒë·ªì v√† l·∫≠p h∆∞·ªõng d·∫´n..."):
            # Prompt Engineering: √âp AI tr·∫£ v·ªÅ JSON c·∫•u tr√∫c chu·∫©n
            system_prompt = """
            B·∫°n l√† m·ªôt chuy√™n gia IELTS Writing Task 1. H√£y ph√¢n t√≠ch ƒë·ªÅ b√†i v√† h√¨nh ·∫£nh ƒë∆∞·ª£c cung c·∫•p.
            Nhi·ªám v·ª•:
            1. X√°c ƒë·ªãnh lo·∫°i bi·ªÉu ƒë·ªì (Line, Bar, Map, Process, Mixed, etc.).
            2. Vi·∫øt h∆∞·ªõng d·∫´n chi ti·∫øt b·∫±ng TI·∫æNG VI·ªÜT cho 4 ph·∫ßn: Introduction, Overview, Body 1, Body 2.
            
            Y√™u c·∫ßu format OUTPUT l√† JSON v·ªõi c√°c key sau:
            {
                "task_type": "Lo·∫°i bi·ªÉu ƒë·ªì (V√≠ d·ª•: Process Diagram)",
                "introduction_guide": "H∆∞·ªõng d·∫´n c√°ch paraphrase ƒë·ªÅ b√†i...",
                "overview_guide": "H∆∞·ªõng d·∫´n vi·∫øt c√¢u nh·∫≠n x√©t chung (xu h∆∞·ªõng/ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t)...",
                "body1_guide": "H∆∞·ªõng d·∫´n chi ti·∫øt nh√≥m th√¥ng tin 1...",
                "body2_guide": "H∆∞·ªõng d·∫´n chi ti·∫øt nh√≥m th√¥ng tin 2..."
            }
            Ch·ªâ tr·∫£ v·ªÅ JSON, kh√¥ng th√™m l·ªùi d·∫´n.
            """
            
            # G·ªçi h√†m AI c·ªßa b·∫°n
            response, model_used = generate_content_with_failover(system_prompt + "\n\nƒê·ªÅ b√†i: " + question_text, img_data)
            
            if response:
                result_json = parse_ai_response(response.text)
                if result_json:
                    st.session_state.guide_data = result_json
                    st.toast("ƒê√£ ph√¢n t√≠ch xong!", icon="‚úÖ")

# --- KHU V·ª∞C TH·ª∞C H√ÄNH ---

if st.session_state.guide_data:
    data = st.session_state.guide_data
    
    st.markdown("---")
    st.info(f"üìå **Lo·∫°i b√†i:** {data.get('task_type', 'Task 1')}")

    # H√†m render t·ª´ng section
    def render_section(title, guide_content, key_name):
        st.markdown(f"### {title}")
        
        # Ph·∫ßn h∆∞·ªõng d·∫´n t·ª´ AI (m√†u x√°m)
        st.markdown(f"""
        <div class="guide-box">
            <div class="guide-title">üí° H∆∞·ªõng d·∫´n {title}:</div>
            {guide_content}
        </div>
        """, unsafe_allow_html=True)
        
        # √î nh·∫≠p li·ªáu
        user_input = st.text_area(f"Vi·∫øt ph·∫ßn {title} c·ªßa b·∫°n:", height=150, key=key_name)
        
        # Word count
        words = len(user_input.split()) if user_input else 0
        st.caption(f"S·ªë t·ª´: {words}")
        return user_input

    # 1. Introduction
    intro = render_section("Introduction", data.get("introduction_guide", ""), "input_intro")
    
    # 2. Overview
    overview = render_section("Overview", data.get("overview_guide", ""), "input_overview")
    
    # 3. Body 1
    body1 = render_section("Body 1", data.get("body1_guide", ""), "input_body1")
    
    # 4. Body 2
    body2 = render_section("Body 2", data.get("body2_guide", ""), "input_body2")

    # T·ªïng k·∫øt
    st.markdown("---")
    total_words = len(intro.split()) + len(overview.split()) + len(body1.split()) + len(body2.split())
    st.metric(label="T·ªïng s·ªë t·ª´ b√†i vi·∫øt", value=total_words)
    
    full_essay = f"{intro}\n\n{overview}\n\n{body1}\n\n{body2}"
    if st.button("üìã Copy to√†n b·ªô b√†i vi·∫øt"):
        st.code(full_essay, language='text')
